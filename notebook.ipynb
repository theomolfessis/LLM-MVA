{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Find all JSON files in the specified directory\n",
    "json_files_train = glob.glob('/Users/theo/Desktop/MVA/Second_Semestre/LLM/Projet-final/ECHR_Dataset/EN_train/*.json')\n",
    "json_files_dev = glob.glob('/Users/theo/Desktop/MVA/Second_Semestre/LLM/Projet-final/ECHR_Dataset/EN_dev/*.json')\n",
    "json_files_test = glob.glob('/Users/theo/Desktop/MVA/Second_Semestre/LLM/Projet-final/ECHR_Dataset/EN_test/*.json')\n",
    "rows_train = []\n",
    "rows_dev = []\n",
    "rows_test = []\n",
    "\n",
    "for file in json_files_train:\n",
    "    with open(file, 'r') as f:\n",
    "        data_train  = json.load(f)\n",
    "        # If needed, process certain fields (e.g., join lists) here:\n",
    "        # data['TEXT'] = ' '.join(data['TEXT'])\n",
    "        rows_train.append(data_train)\n",
    "\n",
    "# Create the global DataFrame\n",
    "df_train = pd.DataFrame(rows_train)\n",
    "\n",
    "\n",
    "for file in json_files_dev:\n",
    "    with open(file, 'r') as f:\n",
    "        data_dev = json.load(f)\n",
    "        # If needed, process certain fields (e.g., join lists) here:\n",
    "        # data['TEXT'] = ' '.join(data['TEXT'])\n",
    "        rows_dev.append(data_dev)\n",
    "\n",
    "# Create the global DataFrame\n",
    "df_dev = pd.DataFrame(rows_dev)\n",
    "\n",
    "for file in json_files_test:\n",
    "    with open(file, 'r') as f:\n",
    "        data_test = json.load(f)\n",
    "        # If needed, process certain fields (e.g., join lists) here:\n",
    "        # data['TEXT'] = ' '.join(data['TEXT'])\n",
    "        rows_test.append(data_test)\n",
    " \n",
    "# Create the global DataFrame\n",
    "df_test = pd.DataFrame(rows_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get binary column for each dataset for violation\n",
    "# List of columns to check\n",
    "columns_to_check = [\n",
    "    'VIOLATED_ARTICLES', 'VIOLATED_PARAGRAPHS', 'VIOLATED_BULLETPOINTS'\n",
    "]\n",
    "\n",
    "# Create the new binary column\n",
    "df_train['VIOLATED'] = df_train[columns_to_check].apply(\n",
    "    lambda row: 1 if any(len(item) > 0 for item in row) else 0,\n",
    "    axis=1\n",
    "\n",
    ")\n",
    "\n",
    "df_dev['VIOLATED'] = df_dev[columns_to_check].apply(\n",
    "    lambda row: 1 if any(len(item) > 0 for item in row) else 0,\n",
    "    axis=1\n",
    "\n",
    ")\n",
    "\n",
    "df_test['VIOLATED'] = df_test[columns_to_check].apply(\n",
    "    lambda row: 1 if any(len(item) > 0 for item in row) else 0,\n",
    "    axis=1\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>LANGUAGEISOCODE</th>\n",
       "      <th>RESPONDENT</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DOCNAME</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>CONCLUSION</th>\n",
       "      <th>JUDGES</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>VIOLATED_ARTICLES</th>\n",
       "      <th>VIOLATED_PARAGRAPHS</th>\n",
       "      <th>VIOLATED_BULLETPOINTS</th>\n",
       "      <th>NON_VIOLATED_ARTICLES</th>\n",
       "      <th>NON_VIOLATED_PARAGRAPHS</th>\n",
       "      <th>NON_VIOLATED_BULLETPOINTS</th>\n",
       "      <th>binary violates</th>\n",
       "      <th>VIOLATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-60310</td>\n",
       "      <td>ENG</td>\n",
       "      <td>TUR</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2002</td>\n",
       "      <td>CASE OF SABUKTEKIN v. TURKEY</td>\n",
       "      <td>1</td>\n",
       "      <td>No violation of Art. 2 concerning the death of...</td>\n",
       "      <td>Matti Pellonpää</td>\n",
       "      <td>[7. On 28 September 1994 the applicant's husba...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13, 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-93292</td>\n",
       "      <td>ENG</td>\n",
       "      <td>POL</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2009</td>\n",
       "      <td>CASE OF GRZEGORZ HULEWICZ v. POLAND (No. 2)</td>\n",
       "      <td>4</td>\n",
       "      <td>No violation of Article 5 - Right to liberty a...</td>\n",
       "      <td>David Thór Björgvinsson;Giovanni Bonello;Lech ...</td>\n",
       "      <td>[8. The applicant was born in 1974 and lives i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-93768</td>\n",
       "      <td>ENG</td>\n",
       "      <td>SVK</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2009</td>\n",
       "      <td>CASE OF DVORACEK AND DVORACKOVA v. SLOVAKIA</td>\n",
       "      <td>3</td>\n",
       "      <td>Remainder inadmissible;Violation of Art. 2 (pr...</td>\n",
       "      <td>David Thór Björgvinsson;Giovanni Bonello;Ján Š...</td>\n",
       "      <td>[5. The first applicant, Mr Ivan Dvořáček, was...</td>\n",
       "      <td>[2, 6]</td>\n",
       "      <td>[6-1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-82483</td>\n",
       "      <td>ENG</td>\n",
       "      <td>TUR</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2007</td>\n",
       "      <td>CASE OF MAHMUT ASLAN v. TURKEY</td>\n",
       "      <td>3</td>\n",
       "      <td>Preliminary objections dismissed (victim, non-...</td>\n",
       "      <td>Nicolas Bratza</td>\n",
       "      <td>[4. The applicant was born in 1959 and lives i...</td>\n",
       "      <td>[13, 6]</td>\n",
       "      <td>[6-1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-61852</td>\n",
       "      <td>ENG</td>\n",
       "      <td>LIE</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2004</td>\n",
       "      <td>CASE OF FROMMELT v. LIECHTENSTEIN</td>\n",
       "      <td>3</td>\n",
       "      <td>Violation of Art. 5-4;Non-pecuniary damage - f...</td>\n",
       "      <td>Georg Ress;Mark Villiger</td>\n",
       "      <td>[6. The applicant was born in 1946., 7. On 14 ...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[5-4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>001-75243</td>\n",
       "      <td>ENG</td>\n",
       "      <td>SVN</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2006</td>\n",
       "      <td>CASE OF GASHI v. SLOVENIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Violation of Art. 6-1;Violation of Art. 13;Non...</td>\n",
       "      <td>David Thór Björgvinsson;John Hedigan</td>\n",
       "      <td>[5. The applicant was born in 1943 and lives i...</td>\n",
       "      <td>[13, 6]</td>\n",
       "      <td>[6-1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>001-23423</td>\n",
       "      <td>ENG</td>\n",
       "      <td>SVK</td>\n",
       "      <td>ADMISSIBILITY</td>\n",
       "      <td>2003</td>\n",
       "      <td>VACLAVIK v. SLOVAKIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Inadmissible</td>\n",
       "      <td>Nicolas Bratza</td>\n",
       "      <td>[The applicant, Mr Dušan Václavík, is a Slovak...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>001-76896</td>\n",
       "      <td>ENG</td>\n",
       "      <td>SRB</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2006</td>\n",
       "      <td>CASE OF MATIJASEVIC v. SERBIA</td>\n",
       "      <td>1</td>\n",
       "      <td>Violation of Art. 6-2;Remainder inadmissible;N...</td>\n",
       "      <td>András Baka;Antonella Mularoni;Elisabet Fura;I...</td>\n",
       "      <td>[4. The applicant was born in 1976 and is curr...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[6-2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>001-78471</td>\n",
       "      <td>ENG</td>\n",
       "      <td>SVK</td>\n",
       "      <td>ADMISSIBILITY</td>\n",
       "      <td>2006</td>\n",
       "      <td>BALAZ AND OTHERS v. SLOVAKIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Inadmissible</td>\n",
       "      <td>Nicolas Bratza</td>\n",
       "      <td>[The applicants are relatives. They are all Sl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>001-4897</td>\n",
       "      <td>ENG</td>\n",
       "      <td>NLD</td>\n",
       "      <td>ADMISSIBILITY</td>\n",
       "      <td>1999</td>\n",
       "      <td>HIBBERT v. THE NETHERLANDS</td>\n",
       "      <td>3</td>\n",
       "      <td>Inadmissible</td>\n",
       "      <td>Elisabeth Palm</td>\n",
       "      <td>[The applicant, a Dutch national, was born in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ITEMID LANGUAGEISOCODE RESPONDENT         BRANCH  DATE  \\\n",
       "0     001-60310             ENG        TUR        CHAMBER  2002   \n",
       "1     001-93292             ENG        POL        CHAMBER  2009   \n",
       "2     001-93768             ENG        SVK        CHAMBER  2009   \n",
       "3     001-82483             ENG        TUR        CHAMBER  2007   \n",
       "4     001-61852             ENG        LIE        CHAMBER  2004   \n",
       "...         ...             ...        ...            ...   ...   \n",
       "7095  001-75243             ENG        SVN        CHAMBER  2006   \n",
       "7096  001-23423             ENG        SVK  ADMISSIBILITY  2003   \n",
       "7097  001-76896             ENG        SRB        CHAMBER  2006   \n",
       "7098  001-78471             ENG        SVK  ADMISSIBILITY  2006   \n",
       "7099   001-4897             ENG        NLD  ADMISSIBILITY  1999   \n",
       "\n",
       "                                          DOCNAME IMPORTANCE  \\\n",
       "0                    CASE OF SABUKTEKIN v. TURKEY          1   \n",
       "1     CASE OF GRZEGORZ HULEWICZ v. POLAND (No. 2)          4   \n",
       "2     CASE OF DVORACEK AND DVORACKOVA v. SLOVAKIA          3   \n",
       "3                  CASE OF MAHMUT ASLAN v. TURKEY          3   \n",
       "4               CASE OF FROMMELT v. LIECHTENSTEIN          3   \n",
       "...                                           ...        ...   \n",
       "7095                    CASE OF GASHI v. SLOVENIA          4   \n",
       "7096                         VACLAVIK v. SLOVAKIA          4   \n",
       "7097                CASE OF MATIJASEVIC v. SERBIA          1   \n",
       "7098                 BALAZ AND OTHERS v. SLOVAKIA          4   \n",
       "7099                   HIBBERT v. THE NETHERLANDS          3   \n",
       "\n",
       "                                             CONCLUSION  \\\n",
       "0     No violation of Art. 2 concerning the death of...   \n",
       "1     No violation of Article 5 - Right to liberty a...   \n",
       "2     Remainder inadmissible;Violation of Art. 2 (pr...   \n",
       "3     Preliminary objections dismissed (victim, non-...   \n",
       "4     Violation of Art. 5-4;Non-pecuniary damage - f...   \n",
       "...                                                 ...   \n",
       "7095  Violation of Art. 6-1;Violation of Art. 13;Non...   \n",
       "7096                                       Inadmissible   \n",
       "7097  Violation of Art. 6-2;Remainder inadmissible;N...   \n",
       "7098                                       Inadmissible   \n",
       "7099                                       Inadmissible   \n",
       "\n",
       "                                                 JUDGES  \\\n",
       "0                                       Matti Pellonpää   \n",
       "1     David Thór Björgvinsson;Giovanni Bonello;Lech ...   \n",
       "2     David Thór Björgvinsson;Giovanni Bonello;Ján Š...   \n",
       "3                                        Nicolas Bratza   \n",
       "4                              Georg Ress;Mark Villiger   \n",
       "...                                                 ...   \n",
       "7095               David Thór Björgvinsson;John Hedigan   \n",
       "7096                                     Nicolas Bratza   \n",
       "7097  András Baka;Antonella Mularoni;Elisabet Fura;I...   \n",
       "7098                                     Nicolas Bratza   \n",
       "7099                                     Elisabeth Palm   \n",
       "\n",
       "                                                   TEXT VIOLATED_ARTICLES  \\\n",
       "0     [7. On 28 September 1994 the applicant's husba...                []   \n",
       "1     [8. The applicant was born in 1974 and lives i...                []   \n",
       "2     [5. The first applicant, Mr Ivan Dvořáček, was...            [2, 6]   \n",
       "3     [4. The applicant was born in 1959 and lives i...           [13, 6]   \n",
       "4     [6. The applicant was born in 1946., 7. On 14 ...               [5]   \n",
       "...                                                 ...               ...   \n",
       "7095  [5. The applicant was born in 1943 and lives i...           [13, 6]   \n",
       "7096  [The applicant, Mr Dušan Václavík, is a Slovak...                []   \n",
       "7097  [4. The applicant was born in 1976 and is curr...               [6]   \n",
       "7098  [The applicants are relatives. They are all Sl...                []   \n",
       "7099  [The applicant, a Dutch national, was born in ...                []   \n",
       "\n",
       "     VIOLATED_PARAGRAPHS VIOLATED_BULLETPOINTS NON_VIOLATED_ARTICLES  \\\n",
       "0                     []                    []               [13, 2]   \n",
       "1                     []                    []                   [5]   \n",
       "2                  [6-1]                    []                    []   \n",
       "3                  [6-1]                    []                    []   \n",
       "4                  [5-4]                    []                    []   \n",
       "...                  ...                   ...                   ...   \n",
       "7095               [6-1]                    []                    []   \n",
       "7096                  []                    []                    []   \n",
       "7097               [6-2]                    []                    []   \n",
       "7098                  []                    []                    []   \n",
       "7099                  []                    []                    []   \n",
       "\n",
       "     NON_VIOLATED_PARAGRAPHS NON_VIOLATED_BULLETPOINTS  binary violates  \\\n",
       "0                         []                        []                0   \n",
       "1                         []                        []                0   \n",
       "2                         []                        []                1   \n",
       "3                         []                        []                1   \n",
       "4                         []                        []                1   \n",
       "...                      ...                       ...              ...   \n",
       "7095                      []                        []                1   \n",
       "7096                      []                        []                0   \n",
       "7097                      []                        []                1   \n",
       "7098                      []                        []                0   \n",
       "7099                      []                        []                0   \n",
       "\n",
       "      VIOLATED  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "7095         1  \n",
       "7096         0  \n",
       "7097         1  \n",
       "7098         0  \n",
       "7099         0  \n",
       "\n",
       "[7100 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert Tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7864d99b2b413ea7be256911fd1497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/382 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfc9136bf954b2d8fb5b4f8b3b0526a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model_bert_tiny = AutoModel.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.1):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Load the pre-trained model\n",
    "        self.bert = AutoModel.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Classification head: Dense layer with tanh activation followed by another Dense layer\n",
    "        self.dense_tanh = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)  # binary classification -> 2 classes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get outputs from BERT; use pooler_output (or outputs[1] if pooler_output is absent)\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output if hasattr(outputs, 'pooler_output') else outputs[1]\n",
    "        # Apply dropout, tanh activation and another dropout\n",
    "        x = self.dropout(pooled_output)\n",
    "        x = self.dense_tanh(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        # Compute logits and probabilities\n",
    "        logits = self.classifier(x)\n",
    "        probs = self.softmax(logits)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/bzcnw1ns6b544bv2hbtjsmmr0000gn/T/ipykernel_27105/707452331.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_train_dev = df_train.append(df_dev, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48a30ba7d4a47e397ac731e74fd4062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 0.6877\n",
      "Epoch 2/30 - Loss: 0.6831\n",
      "Epoch 3/30 - Loss: 0.6711\n",
      "Epoch 4/30 - Loss: 0.6508\n",
      "Epoch 5/30 - Loss: 0.6200\n",
      "Epoch 6/30 - Loss: 0.5834\n",
      "Epoch 7/30 - Loss: 0.5515\n",
      "Epoch 8/30 - Loss: 0.5238\n",
      "Epoch 9/30 - Loss: 0.5002\n",
      "Epoch 10/30 - Loss: 0.4776\n",
      "Epoch 11/30 - Loss: 0.4550\n",
      "Epoch 12/30 - Loss: 0.4291\n",
      "Epoch 13/30 - Loss: 0.4072\n",
      "Epoch 14/30 - Loss: 0.3934\n",
      "Epoch 15/30 - Loss: 0.3816\n",
      "Epoch 16/30 - Loss: 0.3741\n",
      "Epoch 17/30 - Loss: 0.3647\n",
      "Epoch 18/30 - Loss: 0.3574\n",
      "Epoch 19/30 - Loss: 0.3525\n",
      "Epoch 20/30 - Loss: 0.3510\n",
      "Epoch 21/30 - Loss: 0.3469\n",
      "Epoch 22/30 - Loss: 0.3457\n",
      "Epoch 23/30 - Loss: 0.3428\n",
      "Epoch 24/30 - Loss: 0.3415\n",
      "Epoch 25/30 - Loss: 0.3397\n",
      "Epoch 26/30 - Loss: 0.3399\n",
      "Epoch 27/30 - Loss: 0.3382\n",
      "Epoch 28/30 - Loss: 0.3360\n",
      "Epoch 29/30 - Loss: 0.3358\n",
      "Epoch 30/30 - Loss: 0.3339\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "\n",
    "# Assume df_train_dev is your combined training+development DataFrame.\n",
    "df_train_dev = df_train.append(df_dev, ignore_index=True)\n",
    "# It must contain the columns:\n",
    "#   \"CONCLUSION\" (input text)\n",
    "#   \"VIOLATED\" (target binary label; e.g., 0 or 1)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, dataframe, text_column, label_column, max_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.text_column = text_column\n",
    "        self.label_column = label_column\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataframe.iloc[idx][self.text_column]\n",
    "        label = self.dataframe.iloc[idx][self.label_column]\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),       # shape: (max_length,)\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),  # shape: (max_length,)\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TextDataset(df_train_dev, text_column='CONCLUSION', label_column='VIOLATED', max_length=128)\n",
    "batch_size = 16\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model and move to device\n",
    "model = BertClassifier(dropout_rate=0.1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up training parameters\n",
    "# Grid-search example: iterate over learning rates in {2e-5, 3e-5, 4e-5, 5e-5}\n",
    "# For demonstration, we use learning_rate = 2e-5. To grid search, wrap the following in a loop.\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 30\n",
    "total_steps = len(dataloader) * num_epochs\n",
    "\n",
    "# Scheduler with 100k warm-up steps (ensure warm-up steps do not exceed total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100000, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 2\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Early stopping check (using training loss as a proxy; ideally, use a dev set loss)\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        epochs_no_improve = 0\n",
    "        # Save the best model checkpoint\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/bzcnw1ns6b544bv2hbtjsmmr0000gn/T/ipykernel_27105/158280306.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9713\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assume df_test is your test DataFrame with the same \"CONCLUSION\" and \"VIOLATED\" columns.\n",
    "test_dataset = TextDataset(df_test, text_column='CONCLUSION', label_column='VIOLATED', max_length=128)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Get predicted labels from softmax probabilities\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal Bert Base uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
